{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  calculate_simmilarity_resnet18 import ResnetSimmilarity\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "from nearpy import Engine\n",
    "from nearpy.hashes import RandomBinaryProjections\n",
    "from nearpy.distances import CosineDistance\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from nearpy.storage import MemoryStorage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form ResnetSimmilarity we can get embedding of a vector \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ResnetSimmilarity()\n",
    "pbar = ProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_one = Image.open(\"./data/flower_data/train/1/image_06734.jpg\")\n",
    "pic_one1 = Image.open(\"./data/flower_data/train/1/image_06734.jpg\")\n",
    "pic_two = Image.open(\"./data/flower_data/train/21/image_06774.jpg\")\n",
    "pic_three = Image.open(\"./data/download.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of our vector space\n",
    "dimension = 2048\n",
    "\n",
    "# Create a random binary hash with 10 bits\n",
    "rbp = RandomBinaryProjections('rbp', 10)\n",
    "\n",
    "\n",
    "msote = MemoryStorage()\n",
    "\n",
    "engine = Engine(dimension, lshashes=[rbp],storage=msote,distance=CosineDistance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the Images to the Hash Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rootdir = 'data/flower_data/train/'\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if '.jpg' in file:\n",
    "        \n",
    "            img_path = os.path.join(subdir, file)\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            img_emb = res.getMapping(img)\n",
    "            img_emb = img_emb.view(-1,2048)\n",
    "            img_emb = img_emb.numpy()\n",
    "            \n",
    "            \n",
    "            engine.store_vector(img_emb[0],file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Image Hashed Table to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.63 s, sys: 200 ms, total: 7.83 s\n",
      "Wall time: 7.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filehandler = open(\"hashed_object.pkl\", 'w')\n",
    "pickle.dump(engine, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Hased Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 s, sys: 192 ms, total: 2.11 s\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filehandler = open(\"hashed_object.pkl\", 'r')\n",
    "en_loaded = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2048)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# image to test query\n",
    "pic_one1_emb = res.getMapping(pic_one1)\n",
    "pic_one1_emb = pic_one1_emb.view(-1,2048)\n",
    "pic_one1_emb = pic_one1_emb.numpy()\n",
    "print(pic_one1_emb.shape)\n",
    "\n",
    "\n",
    "query = pic_one1_emb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query on one image and get simmilarity result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('image_07478.jpg', 0.0037085279696490447)\n",
      "('image_02092.jpg', 0.0037371145664987226)\n",
      "('image_02409.jpg', 0.003747304477802915)\n",
      "('image_06762.jpg', 0.003758918024777236)\n",
      "('image_07498.jpg', 0.003764658954826694)\n",
      "('image_07486.jpg', 0.0037659344141985907)\n",
      "('image_06734.jpg', 0.003769805311141905)\n",
      "('image_05609.jpg', 0.0037767262244376987)\n",
      "('image_02080.jpg', 0.0037777438848867195)\n",
      "('image_02814.jpg', 0.003779756883063312)\n",
      "CPU times: user 88 ms, sys: 88 ms, total: 176 ms\n",
      "Wall time: 59 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N = en_loaded.neighbours(query)\n",
    "for i in range(len(N)):\n",
    "    print(N[i][1],N[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch0.4]",
   "language": "python",
   "name": "conda-env-pytorch0.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
